//==============================================================================
// Copyright 2018-2020 Kitware, Inc., Kitware SAS
// Author: Guilbert Pierre (Kitware SAS)
//         Cadart Nicolas (Kitware SAS)
// Creation date: 2018-03-27
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//==============================================================================

// This slam algorithm is inspired by the LOAM algorithm:
// J. Zhang and S. Singh. LOAM: Lidar Odometry and Mapping in Real-time.
// Robotics: Science and Systems Conference (RSS). Berkeley, CA, July 2014.

// The algorithm is composed of three sequential steps:
//
// - Keypoints extraction: this step consists of extracting keypoints over
// the points clouds. To do that, the laser lines / scans are treated independently.
// The laser lines are projected onto the XY plane and are rescaled depending on
// their vertical angle. Then we compute their curvature and create two classes of
// keypoints. The edges keypoints which correspond to points with a high curvature
// and planar points which correspond to points with a low curvature.
//
// - Ego-Motion: this step consists of recovering the motion of the lidar
// sensor between two frames (two sweeps). The motion is modelized by a constant
// velocity and angular velocity between two frames (i.e null acceleration).
// Hence, we can parameterize the motion by a rotation and translation per sweep / frame
// and interpolate the transformation inside a frame using the timestamp of the points.
// Since the points clouds generated by a lidar are sparse we can't design a
// pairwise match between keypoints of two successive frames. Hence, we decided to use
// a closest-point matching between the keypoints of the current frame
// and the geometric features derived from the keypoints of the previous frame.
// The geometric features are lines or planes and are computed using the edges
// and planar keypoints of the previous frame. Once the matching is done, a keypoint
// of the current frame is matched with a plane / line (depending of the
// nature of the keypoint) from the previous frame. Then, we recover R and T by
// minimizing the function f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2).
// Which can be writen f(R, T) = sum((R*X+T-P).t*A*(R*X+T-P)) where:
// - X is a keypoint of the current frame
// - P is a point of the corresponding line / plane
// - A = (n*n.t) with n being the normal of the plane
// - A = (I - n*n.t).t * (I - n*n.t) with n being a director vector of the line
// Since the function f(R, T) is a non-linear mean square error function
// we decided to use the Levenberg-Marquardt algorithm to recover its argmin.
//
// - Localization: This step consists of refining the motion recovered in the Ego-Motion
// step and to add the new frame in the environment map. Thanks to the ego-motion
// recovered at the previous step it is now possible to estimate the new position of
// the sensor in the map. We use this estimation as an initial point (R0, T0) and we
// perform an optimization again using the keypoints of the current frame and the matched
// keypoints of the map (and not only the previous frame this time!). Once the position in the
// map has been refined from the first estimation it is then possible to update the map by
// adding the keypoints of the current frame into the map.
//
// In the following programs, three 3D coordinates system are used :
// - LIDAR {L} : attached to the geometric center of the LiDAR sensor. The
//   coordinates of the received pointclouds are expressed in this system.
//   LIDAR is rigidly linked (static transform) to BASE.
// - BASE  {B} : attached to the origin of the moving body (e.g. vehicle). We
//   are generally interested in tracking an other point of the moving body than
//   the LiDAR's (for example, we prefer to track the GPS antenna pose).
// - WORLD {W} : The world coordinate system {W} coincides with BASE at the
//   initial position. The output trajectory describes BASE origin in WORLD.

// GENERIC
#include <ctime>

// LOCAL
#include "Slam.h"
#include "Utilities.h"
#include "KDTreePCLAdaptor.h"
#include "ConfidenceEstimators.h"

// CERES
#include <ceres/solver.h>
// PCL
#include <pcl/common/common.h>
#include <pcl/common/transforms.h>
#include <pcl/io/pcd_io.h>

// EIGEN
#include <Eigen/Dense>

#define PRINT_VERBOSE(minVerbosityLevel, stream) if (this->mVerbosity >= (minVerbosityLevel)) {std::cout << stream << std::endl;}
#define IF_VERBOSE(minVerbosityLevel, command) if (this->mVerbosity >= (minVerbosityLevel)) { command; }

namespace LidarSlam
{

using KDTree = KDTreePCLAdaptor<Slam::Point>;

namespace Utils
{
namespace
{

//-----------------------------------------------------------------------------
//! Approximate pointcloud memory size
inline size_t PointCloudMemorySize(const Slam::PointCloud& cloud)
{
  return (sizeof(cloud) + (sizeof(Slam::PointCloud::PointType) * cloud.size()));
}

} // end of anonymous namespace
} // end of Utils namespace

//==============================================================================
//   Main SLAM use
//==============================================================================

//-----------------------------------------------------------------------------
Slam::Slam()
{
  // Allocate a default Keypoint Extractor for device 0
  mKeyPointsExtractors[0] = std::make_shared<SpinningSensorKeypointExtractor>();

  // Allocate maps
  for (auto k : mUsableKeypoints)
  {
      mLocalMaps[k] = std::make_shared<RollingGrid>();
  }

  // Set default maps parameters
  if (mUseKeypoints[EDGE])
    InitMap(EDGE);

  if (mUseKeypoints[INTENSITY_EDGE])
    InitMap(INTENSITY_EDGE);

  if (mUseKeypoints[PLANE])
    InitMap(PLANE);

  if (mUseKeypoints[BLOB])
    InitMap(BLOB);

  // Reset SLAM internal state
  Reset();
}

//-----------------------------------------------------------------------------
void Slam::InitMap(Keypoint k)
{
  // Allocate map
  mLocalMaps[k] = std::make_shared<RollingGrid>();

  // Set default maps parameters
  mLocalMaps[k]->SetVoxelResolution(10.);
  mLocalMaps[k]->SetGridSize(50);

  switch(k)
  {
    case EDGE:
      mLocalMaps[k]->SetLeafSize(0.3);
      break;
    case INTENSITY_EDGE:
      mLocalMaps[k]->SetLeafSize(0.3);
      break;
    case PLANE:
      mLocalMaps[k]->SetLeafSize(0.6);
      break;
    case BLOB:
      mLocalMaps[k]->SetLeafSize(0.3);
      break;
    default:
      PRINT_ERROR("Unknown keypoint type");
      break;
  }
}

//-----------------------------------------------------------------------------
void Slam::Reset(bool resetLog)
{
  // Reset keypoints maps
  this->ClearMaps();

  // Reset keyframes
  mKfLastPose = Eigen::Isometry3d::Identity();
  mKfCounter = 0;

  // n-DoF parameters
  mTworld = Eigen::Isometry3d::Identity();
  mTworldInit = Eigen::Isometry3d::Identity();
  mTrelative = Eigen::Isometry3d::Identity();
  mWithinFrameMotion.SetTransforms(Eigen::Isometry3d::Identity(), Eigen::Isometry3d::Identity());

  // Reset pose uncertainty
  mLocalizationUncertainty = LocalOptimizer::RegistrationError();

  // Reset point clouds
  mCurrentFrames.clear();
  mRegisteredFrame.reset(new PointCloud);
  mCurrentFrames.emplace_back(new PointCloud);
  for (auto k : mUsableKeypoints)
  {
    mCurrentRawKeypoints[k].reset(new PointCloud);
    mCurrentUndistortedKeypoints[k].reset(new PointCloud);
    mCurrentWorldKeypoints[k].reset(new PointCloud);
  }

  // Reset keypoints matching results
  for (auto k : mUsableKeypoints)
  {
    mEgoMotionMatchingResults[k] = KeypointsMatcher::MatchingResults();
    mLocalizationMatchingResults[k] = KeypointsMatcher::MatchingResults();
  }

  // Reset external sensor managers
  // WARNING : if offline process, measurements should be reloaded from
  // outside this lib. Moreover, landmark managers lost their absolute poses,
  // they would need to be reloaded too.
  this->ResetSensors(true);

  // Reset log history
  if (resetLog)
  {
    // Reset logged keypoints
    mNbrFrameProcessed = 0;
    mLogStates.clear();

    // Reset processing duration timers
    Utils::Timer::Reset();
  }
}

//-----------------------------------------------------------------------------
void Slam::SetNbThreads(int n)
{
    // Set number of threads for main processes
    mNbThreads = n;

    // Set number of threads for keypoints extraction
    for (const auto& kv : mKeyPointsExtractors)
        kv.second->SetNbThreads(n);
}

//-----------------------------------------------------------------------------
void Slam::EnableKeypointType(Keypoint k, bool enabled)
{
    mUseKeypoints[k] = enabled;
    if (enabled)
    {
        if (!mLocalMaps.count(k))
            this->InitMap(k);

        if (!mCurrentRawKeypoints.count(k))
            mCurrentRawKeypoints[k].reset(new PointCloud);

        if (!mCurrentUndistortedKeypoints.count(k))
            mCurrentUndistortedKeypoints[k].reset(new PointCloud);

        if (!mCurrentWorldKeypoints.count(k))
            mCurrentWorldKeypoints[k].reset(new PointCloud);

        mEgoMotionMatchingResults[k] = KeypointsMatcher::MatchingResults();
        mLocalizationMatchingResults[k] = KeypointsMatcher::MatchingResults();
    }
}

//-----------------------------------------------------------------------------
bool Slam::KeypointTypeEnabled(Keypoint k) const
{
    if (!mUseKeypoints.count(k))
        return false;

    return mUseKeypoints.at(k);
}

//-----------------------------------------------------------------------------
void Slam::AddFrames(const std::vector<PointCloud::Ptr>& frames)
{
  Utils::Timer::Init("SLAM frame processing");

  // Check that input frames are correct and can be processed
  if (!this->CheckFrames(frames))
    return;
  mCurrentFrames = frames;
  mCurrentTime_sec = Utils::PclStampToSec(mCurrentFrames[0]->header.stamp);

  // Set init pose (can have been modified by global optimization / reset)
  // 1) To ensure a smooth local SLAM, the global optimization must refine
  // poses relatively to last pose, i.e, last pose must be fixed.
  // 2) To ensure a fix reference point, the global optimization must refine
  // poses relatively to starting point, i.e, last pose can have changed.
  // If LogStates empty, do not modify Tworld (must be identity after Reset)
  if (!mLogStates.empty())
    mTworld = mLogStates.back().Isometry;
  else
    mTworld = mTworldInit;

  // Create UsableKeypointTypes for new frame
  // The keypoints cannot be chosen while processing a frame
  // because it impacts all the maps structure along the process
  mUsableKeypoints.clear();
  for (auto k : KeypointTypes)
  {
    if (mUseKeypoints[k])
      mUsableKeypoints.push_back(k);
  }

  PRINT_VERBOSE(2, "\n#########################################################");
  PRINT_VERBOSE(1, "Processing frame " << mNbrFrameProcessed << std::fixed << std::setprecision(9) <<
                   " (at time " << mCurrentTime_sec << ")" << std::scientific);
  PRINT_VERBOSE(2, "#########################################################\n");

  // Compute the edge and planar keypoints
  IF_VERBOSE(3, Utils::Timer::Init("Keypoints extraction"));
  this->ExtractKeypoints();
  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Keypoints extraction"));

  // Estimate Trelative by extrapolating new pose with a constant velocity model
  // and/or registering current frame on previous one
  IF_VERBOSE(3, Utils::Timer::Init("Ego-Motion"));
  this->ComputeEgoMotion();
  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Ego-Motion"));

  if ((mWheelOdomManager && mWheelOdomManager->CanBeUsedLocally()) ||
      (mGravityManager && mGravityManager->CanBeUsedLocally()) ||
       this->LmCanBeUsedLocally() ||
      (mPoseManager && mPoseManager->CanBeUsedLocally()))
  {
    IF_VERBOSE(3, Utils::Timer::Init("External sensor constraints computation"));
    this->ComputeSensorConstraints();
    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("External sensor constraints computation"));
  }

  // Perform Localization : update Tworld from map and current frame keypoints
  // and optionally undistort keypoints clouds based on ego-motion
  IF_VERBOSE(3, Utils::Timer::Init("Localization"));
  this->Localization();
  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Localization"));

  // Compute and check pose confidence estimators
  // Must be set before maps update because the overlap computation
  // requires the current KdTree. This KdTree is reset in the maps update.
  if (mOverlapSamplingRatio > 0 || mTimeWindowDuration > 0)
  {
    IF_VERBOSE(3, Utils::Timer::Init("Confidence estimators computation"));
    if (mOverlapSamplingRatio > 0)
      this->EstimateOverlap();
    if (mTimeWindowDuration > 0)
      this->CheckMotionLimits();
    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Confidence estimators computation"));
  }

  // Check if the frame is a keyframe
  mIsKeyFrame = this->CheckKeyFrame();
  if (mIsKeyFrame)
  {
    // Notify current frame to be a new keyframe
    mKfCounter++;
    mKfLastPose = mTworld;
  }

  if (mValid || mIsKeyFrame)
  {
    // Update the tags if requested
    if (mLandmarkConstraintLocal)
    {
      for (auto& idLm : mLandmarksManagers)
      {
        if (idLm.second.UpdateAbsolutePose(mTworld, mCurrentTime_sec))
          PRINT_VERBOSE(3, "Updating reference pose of tag #" << idLm.first << " to "<<idLm.second.GetAbsolutePose().transpose());
      }
    }

    // Update keypoints maps if required: add current keypoints to map using Tworld
    // If mapping mode is ADD_KPTS_TO_FIXED_MAP the initial map points will remain untouched
    // If mapping mode is UPDATE, the initial map points can disappear.
    if ((mMapUpdate == MappingMode::ADD_KPTS_TO_FIXED_MAP
        || mMapUpdate == MappingMode::UPDATE)
        && mIsKeyFrame)
    {
      IF_VERBOSE(3, Utils::Timer::Init("Maps update"));
      this->UpdateMapsUsingTworld();
      IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Maps update"));
    }

    // Log current frame processing results : pose, covariance and keypoints.
    IF_VERBOSE(3, Utils::Timer::Init("Logging"));
    this->LogCurrentFrameState();
    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Logging"));
  }

  // Motion and localization parameters estimation information display
  if (mVerbosity >= 2)
  {
    SET_COUT_FIXED_PRECISION(3);
    std::cout << "========== SLAM results ==========\n";
    if (mUndistortion)
    {
      Eigen::Isometry3d motion = mWithinFrameMotion.GetTransformRange();
      std::cout << "Within frame motion:\n"
                   " translation = [" << motion.translation().transpose()                                        << "] m\n"
                   " rotation    = [" << Utils::Rad2Deg(Utils::RotationMatrixToRPY(motion.linear())).transpose() << "] 째\n";
    }
    std::cout << "Ego-Motion:\n"
                 " translation = [" << mTrelative.translation().transpose()                                        << "] m\n"
                 " rotation    = [" << Utils::Rad2Deg(Utils::RotationMatrixToRPY(mTrelative.linear())).transpose() << "] 째\n"
                 "Localization:\n"
                 " position    = [" << mTworld.translation().transpose()                                        << "] m\n"
                 " orientation = [" << Utils::Rad2Deg(Utils::RotationMatrixToRPY(mTworld.linear())).transpose() << "] 째" << std::endl;
    RESET_COUT_FIXED_PRECISION;
  }

  if (mVerbosity >= 5)
  {
    SET_COUT_FIXED_PRECISION(3);
    std::cout << "========== Memory usage ==========\n";
    std::map<Keypoint, unsigned int> points;
    std::map<Keypoint, unsigned int> memory;

    // Initialize number of points and memory per keypoint type
    for (auto k : mUsableKeypoints)
    {
      points[k] = 0;
      memory[k] = 0;
    }
    // Sum points and memory allocated of each keypoints cloud
    for (auto const& st: mLogStates)
    {
      for (auto k : mUsableKeypoints)
      {
        points[k] += st.Keypoints.at(k)->PointsSize();
        memory[k] += st.Keypoints.at(k)->MemorySize();
      }
    }

    // Print keypoints memory usage
    for (auto k : mUsableKeypoints)
    {
      std::cout << Utils::Capitalize(Utils::Plural(KeypointTypeNames.at(k)))<< " log  : "
                << mLogStates.size() << " frames, "
                << points[k] * 1e-6 << " points, "
                << memory[k] << " MB\n";

    }
    RESET_COUT_FIXED_PRECISION;
  }

  // Frame processing duration
  mLatency = Utils::Timer::Stop("SLAM frame processing");
  mNbrFrameProcessed++;
  IF_VERBOSE(1, Utils::Timer::StopAndDisplay("SLAM frame processing"));
}

//-----------------------------------------------------------------------------
void Slam::ComputeSensorConstraints()
{
  if (mWheelOdomManager && mWheelOdomManager->CanBeUsedLocally() &&
      mWheelOdomManager->ComputeConstraint(mCurrentTime_sec))
    PRINT_VERBOSE(3, "Wheel odometry constraint added")
  if (mGravityManager && mGravityManager->CanBeUsedLocally() &&
      mGravityManager->ComputeConstraint(mCurrentTime_sec))
    PRINT_VERBOSE(3, "IMU gravity constraint added")
  if (this->LmCanBeUsedLocally())
  {
    for (auto& idLm : mLandmarksManagers)
    {
      PRINT_VERBOSE(3, "Checking state of tag #" << idLm.first)
      if (idLm.second.ComputeConstraint(mCurrentTime_sec))
        PRINT_VERBOSE(3, "\t Adding constraint for tag #" << idLm.first)
    }
  }
  if (mPoseManager && mPoseManager->CanBeUsedLocally())
  {
    if (!mLogStates.empty())
    {
      // Update last pose information because the external pose constraint is relative
      // The last pose logged corresponds to last lidar frame
      mPoseManager->SetPrevLidarTime(mLogStates.back().Time);
      mPoseManager->SetPrevPoseTransform(mLogStates.back().Isometry);
      if (mPoseManager->ComputeConstraint(mCurrentTime_sec))
        PRINT_VERBOSE(3, "External pose constraint added")
    }
  }
}

//-----------------------------------------------------------------------------
void Slam::UpdateMaps()
{
  // The iteration is not directly on Keypoint types
  // because of openMP behaviour which needs int iteration on MSVC
  int nbKeypointTypes = static_cast<int>(mUsableKeypoints.size());
  #pragma omp parallel for num_threads(std::min(mNbThreads, nbKeypointTypes))
  for (int i = 0; i < nbKeypointTypes; ++i)
  {
    Keypoint k = static_cast<Keypoint>(mUsableKeypoints[i]);
    mLocalMaps[k]->Clear();
    PointCloud::Ptr keypoints(new PointCloud);
    for (auto& state : mLogStates)
    {
      if (!state.IsKeyFrame)
        continue;

      // Keypoints are stored undistorted : because of the keyframes mechanism,
      // undistortion cannot be refined during pose graph
      // We rely on a good first estimation of the in-frame motion
      keypoints.reset(new PointCloud);
      PointCloud::Ptr undistortedKeypoints = state.Keypoints[k]->GetCloud();
      pcl::transformPointCloud(*undistortedKeypoints, *keypoints, state.Isometry.matrix().cast<float>());

      mLocalMaps[k]->Add(keypoints, false);
    }
    // Roll to center onto last pose
    Eigen::Vector4f minPoint, maxPoint;
    pcl::getMinMax3D(*keypoints, minPoint, maxPoint);
    mLocalMaps[k]->Roll(minPoint.head<3>().array(), maxPoint.head<3>().array());
  }
}

//-----------------------------------------------------------------------------
bool Slam::OptimizeGraph()
{
    #ifdef USE_G2O
    // Check if graph can be optimized
    if (!this->LmHasData() && !this->GpsHasData())
    {
        PRINT_WARNING("No external constraint found, graph cannot be optimized");
        return false;
    }

    PoseGraphOptimizer graphManager;
    graphManager.SetFixFirst(mFixFirstVertex);
    graphManager.SetFixLast(mFixLastVertex);

    // Clear the graph
    graphManager.ResetGraph();

    // Init pose graph optimizer
    graphManager.SetNbIteration(mNbGraphIterations);
    graphManager.SetVerbose(mVerbosity >= 2);
    graphManager.SetSaveG2OFile(!mG2oFileName.empty());
    graphManager.SetG2OFileName(mG2oFileName);

    // Add new SLAM states to graph
    graphManager.AddLidarStates(mLogStates);

    IF_VERBOSE(1, Utils::Timer::Init("Pose graph optimization"));
    IF_VERBOSE(3, Utils::Timer::Init("PGO : optimization"));

    // Boolean to store the info "there is at least one external constraint in the graph"
    bool externalConstraint = false;

    // Look for landmark constraints
    if (this->LmHasData())
    {
        // Allow the rotation of the covariances when interpolating the measurements
        this->SetLandmarkCovarianceRotation(true);
        // Set the landmark detector calibration
        graphManager.AddExternalSensor(mLmDetectorCalibration, int(ExternalSensor::LANDMARK_DETECTOR));

        for (auto& idLm : mLandmarksManagers)
        {
            // Shortcut to current manager
            auto& lm = idLm.second;

            // Add landmark to the graph
            Eigen::Vector6d lmPose = lm.GetAbsolutePose();
            Eigen::Isometry3d lmTransfo = Utils::XYZRPYtoIsometry(lmPose.data());
            graphManager.AddLandmark(lmTransfo, idLm.first, lm.GetPositionOnly());

            // Add landmarks constraint to the graph
            lm.SetVerbose(false);
            for (auto& s : mLogStates)
            {
                ExternalSensors::LandmarkMeasurement lmSynchMeasure; // Virtual landmark measure with synchronized timestamp and no calibration applied
                if (!lm.ComputeSynchronizedMeasure(s.Time, lmSynchMeasure))
                    continue;
                // Add synchronized landmark observations to the graph
                graphManager.AddLandmarkConstraint(s.Index, idLm.first, lmSynchMeasure, lm.GetPositionOnly());
                externalConstraint = true;
            }
            lm.SetVerbose(mVerbosity >= 3);
        }

        // Reset the rotate covariance member to not rotate covariances
        // in future local constraints building
        this->SetLandmarkCovarianceRotation(false);
    }

    // Look for GPS constraints
    if (this->GpsHasData())
    {
        graphManager.AddExternalSensor(mGpsManager->GetCalibration(), int(ExternalSensor::GPS));
        for (auto& s : mLogStates)
        {
            ExternalSensors::GpsMeasurement gpsSynchMeasure; // Virtual GPS measure in SLAM reference frame with synchronized timestamp
            if (!mGpsManager->ComputeSynchronizedMeasureOffset(s.Time, gpsSynchMeasure))
                continue;

            // Add synchronized gps measurement to the graph
            graphManager.AddGpsConstraint(s.Index, gpsSynchMeasure);
            externalConstraint = true;
        }
    }

    if (!externalConstraint)
    {
        PRINT_ERROR("No external constraints exist. Pose graph can not be optimized");
        return false;
    }

    auto statesInit = mLogStates;

    // Run pose graph optimization
    if (!graphManager.Process(mLogStates))
    {
        PRINT_ERROR("Pose graph optimization failed.");
        return false;
    }

    // WARNING : covariances are not updated at each graph optimization
    // because g2o does not allow to reach them.
    // Covariances rotation is mandatory if covariances are to be used again afterwards
    auto itStates = mLogStates.begin();
    auto itInit = statesInit.begin();
    while (itInit != statesInit.end())
    {
        // Compute relative transform
        Eigen::Isometry3d Trel = itInit->Isometry.inverse() * itStates->Isometry;
        Eigen::Vector6d pose = Utils::IsometryToXYZRPY(itInit->Isometry);
        CeresTools::RotateCovariance(pose, itStates->Covariance, Trel); // new = init * Trel
        ++itStates;
        ++itInit;
    }

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("PGO : optimization"));

    // Update the maps
    IF_VERBOSE(3, Utils::Timer::Init("PGO : maps update"));
    this->UpdateMaps();
    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("PGO : maps update"));

    // The last pose has to be updated with new optimized pose
    this->SetWorldTransformFromGuess(mLogStates.back().Isometry);

    IF_VERBOSE(1, Utils::Timer::StopAndDisplay("Pose graph optimization"));

    return true;

#else
    PRINT_ERROR("SLAM graph optimization requires G2O, but it was not found.");
    return false;
#endif  // USE_G2O
}

//-----------------------------------------------------------------------------
void Slam::SetWorldTransformFromGuess(const Eigen::Isometry3d& poseGuess)
{
    // Store pose in case of reinitialization need
    mTworldInit = poseGuess;

    // Set current pose
    mTworld = poseGuess;

    // Ego-Motion estimation is not valid anymore since we imposed a discontinuity.
    // We reset previous pose so that previous ego-motion extrapolation results in Identity matrix.
    // We reset current frame keypoints so that ego-motion registration will be skipped for next frame.
    if (!mLogStates.empty())
        mLogStates.back().Isometry = mTworld;

    for (auto k : mUsableKeypoints)
        mCurrentRawKeypoints[k].reset(new PointCloud);
}

//-----------------------------------------------------------------------------
void Slam::SaveMapsToPCD(const std::string& filePrefix, PCDFormat pcdFormat, bool filtered) const
{
  IF_VERBOSE(3, Utils::Timer::Init("Keypoints maps saving to PCD"));

  // Save keypoint maps
  for (auto k : mUsableKeypoints)
    savePointCloudToPCD(filePrefix + Utils::Plural(KeypointTypeNames.at(k)) + ".pcd",  *this->GetMap(k, filtered),  pcdFormat, true);

  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Keypoints maps saving to PCD"));
}

//-----------------------------------------------------------------------------
void Slam::LoadMapsFromPCD(const std::string& filePrefix, bool resetMaps)
{
  IF_VERBOSE(3, Utils::Timer::Init("Keypoints maps loading from PCD"));

  // In most of the cases, we would like to reset SLAM internal maps before
  // loading new maps to avoid conflicts.
  if (resetMaps)
    this->ClearMaps();

  for (auto k : mUsableKeypoints)
  {
    std::string path = filePrefix + Utils::Plural(KeypointTypeNames.at(k)) + ".pcd";
    PointCloud::Ptr keypoints(new PointCloud);
    if (pcl::io::loadPCDFile(path, *keypoints) == 0)
    {
      std::cout << "SLAM keypoints map successfully loaded from " << path << std::endl;
      // If mapping mode is NONE or ADD_DECAYING_KPTS, the first map points are fixed,
      // else, the initial map points can be updated
      bool fixedMap = mMapUpdate == MappingMode::NONE || mMapUpdate == MappingMode::ADD_KPTS_TO_FIXED_MAP;
      mLocalMaps[k]->Add(keypoints, fixedMap);
    }
  }
  // TODO : load/use map origin (in which coordinates?) in title or VIEWPOINT field
  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Keypoints maps loading from PCD"));
}

//==============================================================================
//   SLAM results getters
//==============================================================================

//-----------------------------------------------------------------------------
Eigen::Isometry3d Slam::GetLatencyCompensatedWorldTransform() const
{
  // Get 2 last transforms
  unsigned int trajectorySize = mLogStates.size();
  if (trajectorySize == 0)
    return Eigen::Isometry3d::Identity();
  else if (trajectorySize == 1)
    return mLogStates.back().Isometry;
  auto itSt = mLogStates.end();
  const LidarState& current = *(--itSt);
  const LidarState& previous = *(--itSt);

  // Linearly compute normalized timestamp of Hpred.
  // We expect H0 and H1 to match with time 0 and 1.
  // If timestamps are not defined or too close, extrapolation is impossible.
  if (std::abs(current.Time - previous.Time) < 1e-6)
  {
    PRINT_WARNING("Unable to compute latency-compensated transform : timestamps undefined or too close.");
    return current.Isometry;
  }
  // If requested extrapolation timestamp is too far from previous frames timestamps, extrapolation is impossible.
  if (std::abs(mLatency / (current.Time - previous.Time)) > mMaxExtrapolationRatio)
  {
    PRINT_WARNING("Unable to compute latency-compensated transform : extrapolation time is too far.");
    return current.Isometry;
  }

  // Extrapolate H0 and H1 to get expected Hpred at current time
  Eigen::Isometry3d Hpred = LinearInterpolation(previous.Isometry, current.Isometry, current.Time + mLatency, previous.Time, current.Time);
  return Hpred;
}

//-----------------------------------------------------------------------------
std::unordered_map<std::string, double> Slam::GetDebugInformation() const
{
  std::unordered_map<std::string, double> map;
  for (Keypoint k : mUsableKeypoints)
  {
    std::string name = "EgoMotion: " + Utils::Plural(KeypointTypeNames.at(k)) + " used";
    map[name] = mEgoMotionMatchingResults.at(k).NbMatches();
  }

  for (auto k : mUsableKeypoints)
  {
    std::string name = "Localization: " + Utils::Plural(KeypointTypeNames.at(k)) + " used";
    map[name] = mLocalizationMatchingResults.at(k).NbMatches();
  }

  map["Localization: position error"]      = mLocalizationUncertainty.PositionError;
  map["Localization: orientation error"]   = mLocalizationUncertainty.OrientationError;
  map["Confidence: overlap"]               = mOverlapEstimation;
  map["Confidence: comply motion limits"]  = mComplyMotionLimits;

  return map;
}

//-----------------------------------------------------------------------------
std::unordered_map<std::string, std::vector<double>> Slam::GetDebugArray() const
{
  auto toDoubleVector = [](auto const& scalars) { return std::vector<double>(scalars.begin(), scalars.end()); };

  std::unordered_map<std::string, std::vector<double>> map;
  for (auto k : mUsableKeypoints)
  {
    std::string name = "EgoMotion: " + KeypointTypeNames.at(k) + " matches";
    map[name]  = toDoubleVector(mEgoMotionMatchingResults.at(k).Rejections);
    name = "EgoMotion: " + KeypointTypeNames.at(k) + " weights";
    map[name]  = mEgoMotionMatchingResults.at(k).Weights;
  }

  for (auto k : mUsableKeypoints)
  {
    std::string name = "Localization: " + KeypointTypeNames.at(k) + " matches";
    map[name]  = toDoubleVector(mLocalizationMatchingResults.at(k).Rejections);
    name = "Localization: " + KeypointTypeNames.at(k) + " weights";
    map[name]  = mLocalizationMatchingResults.at(k).Weights;
  }

  return map;
}

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::GetRegisteredFrame()
{
  // If the input points have not been aggregated to WORLD coordinates yet,
  // transform and aggregate them
  if (mRegisteredFrame->header.stamp != mCurrentFrames[0]->header.stamp)
    mRegisteredFrame = this->AggregateFrames(mCurrentFrames, true);
  return mRegisteredFrame;
}

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::GetMap(Keypoint k, bool clean) const
{
  PointCloud::Ptr map = mLocalMaps.at(k)->Get(clean);
  map->header = Utils::BuildPclHeader(mCurrentFrames[0]->header.stamp,
                                      mWorldFrameId,
                                      mNbrFrameProcessed);
  return map;
}

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::GetTargetSubMap(Keypoint k) const
{
  PointCloud::Ptr subMap = mLocalMaps.at(k)->GetSubMap();
  subMap->header = Utils::BuildPclHeader(mCurrentFrames[0]->header.stamp,
                                         mWorldFrameId,
                                         mNbrFrameProcessed);
  return subMap;
}

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::GetKeypoints(Keypoint k, bool worldCoordinates)
{
  // Return keypoints in BASE coordinates
  if (!worldCoordinates)
    return mCurrentUndistortedKeypoints.at(k);

  // Return keypoints in WORLD coordinates
  // If the keypoints have not been transformed yet to WORLD coordinates, perform transformation
  if (mCurrentWorldKeypoints.at(k)->header.stamp != mCurrentUndistortedKeypoints.at(k)->header.stamp)
    mCurrentWorldKeypoints[k] = this->TransformPointCloud(mCurrentUndistortedKeypoints[k],
                                                               mTworld, mWorldFrameId);
  return mCurrentWorldKeypoints.at(k);
}

//==============================================================================
//   Main SLAM steps
//==============================================================================

//-----------------------------------------------------------------------------
bool Slam::CheckFrames(const std::vector<PointCloud::Ptr>& frames)
{
  // Check input frames and return if they are all empty
  bool allFramesEmpty = true;
  for (unsigned int i = 0; i < frames.size(); ++i)
  {
    if (!frames[i] || !frames[i]->empty())
      allFramesEmpty = false;
    else
      PRINT_WARNING("SLAM input frame " << i << " is an empty pointcloud : frame ignored.");
  }
  if (allFramesEmpty)
  {
    PRINT_ERROR("SLAM input only contains empty pointclouds : exiting.");
    return false;
  }

  // Skip frames if it has the same timestamp as previous ones (will induce problems in extrapolation)
  if (frames[0]->header.stamp == mCurrentFrames[0]->header.stamp)
  {
    PRINT_ERROR("SLAM frames have the same timestamp (" << frames[0]->header.stamp << ") as previous ones : frames ignored.");
    return false;
  }

  // Check frame dropping
  for (unsigned int i = 0; i < frames.size(); ++i)
  {
    unsigned int droppedFrames = frames[i]->header.seq - mPreviousFramesSeq[i] - 1;
    if ((mPreviousFramesSeq[i] > 0) && (droppedFrames > 0))
      PRINT_WARNING(droppedFrames << " frame(s)" << (frames.size() > 1 ? " from LiDAR device " + std::to_string(i) : "") << " were dropped by SLAM\n");
    mPreviousFramesSeq[i] = frames[i]->header.seq;
  }

  return true;
}

//-----------------------------------------------------------------------------
void Slam::ExtractKeypoints()
{
  PRINT_VERBOSE(2, "========== Keypoints extraction ==========");

  // Current keypoints become previous ones
  mPreviousRawKeypoints = mCurrentRawKeypoints;

  // Extract keypoints from each input cloud
  std::map<Keypoint, std::vector<PointCloud::Ptr>> keypoints;
  for (const auto& frame: mCurrentFrames)
  {
    // If the frame is empty, ignore it
    if (frame->empty())
      continue;

    // Get keypoints extractor to use for this LiDAR device
    int lidarDevice = frame->front().device_id;
    // Check if KE exists
    if (!mKeyPointsExtractors.count(lidarDevice))
    {
      // If KE does not exist but we are only using a single KE, use default one
      if (mKeyPointsExtractors.size() == 1)
      {
        PRINT_WARNING("Input frame comes from LiDAR device " << lidarDevice
                    << " but no keypoints extractor has been set for this device : using default extractor for device 0.");
        lidarDevice = 0;
      }
      // Otherwise ignore frame
      else
      {
        PRINT_ERROR("Input frame comes from LiDAR device " << lidarDevice
                    << " but no keypoints extractor has been set for this device : ignoring frame.");
        continue;
      }
    }
    KeypointExtractorPtr& ke = mKeyPointsExtractors[lidarDevice];
    ke->Enable(mUsableKeypoints);
    // Extract keypoints from this frame
    ke->ComputeKeyPoints(frame);
    for (auto k : mUsableKeypoints)
      keypoints[k].push_back(ke->GetKeypoints(k));
  }

  // Merge all keypoints extracted from different frames together
  for (auto k : mUsableKeypoints)
    mCurrentRawKeypoints[k] = this->AggregateFrames(keypoints[k], false);

  if (mVerbosity >= 2)
  {
    std::cout << "Extracted features : ";
    for (auto k : mUsableKeypoints)
      std::cout << mCurrentRawKeypoints[k]->size() << " " << Utils::Plural(KeypointTypeNames.at(k)) << " ";
    std::cout << std::endl;
  }
}

//-----------------------------------------------------------------------------
bool Slam::InitTworldWithPoseMeasurement(double time)
{
  // Compute synchronized pose
  if (!mPoseManager)
  {
    PRINT_WARNING("No external pose manager : Lidar pose not initialized")
    return false;
  }
  ExternalSensors::PoseMeasurement synchMeas; // Virtual measure with synchronized timestamp and calibration applied
  if (!mPoseManager->ComputeSynchronizedMeasureBase(time, synchMeas))
  {
    PRINT_WARNING("Cannot find synchronized pose measurement : Lidar pose not initialized")
    return false;
  }

  Eigen::Isometry3d odom2Ext = mTworld.inverse() * synchMeas.Pose;
  // Update trajectory
  if (!mLogStates.empty())
  {
    for (auto& s : mLogStates)
    {
      // Rotate covariance
      Eigen::Vector6d initPose = Utils::IsometryToXYZRPY(s.Isometry);
      CeresTools::RotateCovariance(initPose, s.Covariance, odom2Ext); // new = init * odom2Ext
      // Transform pose
      s.Isometry = s.Isometry * odom2Ext;
    }
    // Update maps
    this->UpdateMaps();
  }
  else
    mTworldInit = mTworld * odom2Ext;

  mTworld = mTworld * odom2Ext;

  PRINT_VERBOSE(1, "Pose initialized with external pose measurement");
  return true;
}

//-----------------------------------------------------------------------------
void Slam::ComputeEgoMotion()
{
  PRINT_VERBOSE(2, "========== Ego-Motion ==========");

  // Reset ego-motion
  mTrelative = Eigen::Isometry3d::Identity();

  bool externalAvailable = false;
  // Linearly extrapolate previous motion to estimate new pose
  if (!mLogStates.empty() &&
      (mEgoMotion == EgoMotionMode::EXTERNAL ||
       mEgoMotion == EgoMotionMode::EXTERNAL_OR_MOTION_EXTRAPOLATION))
  {
    if (this->PoseHasData())
    {
      ExternalSensors::PoseMeasurement synchPreviousPoseMeas; // Virtual measure with synchronized timestamp and calibration applied
      if (mPoseManager->ComputeSynchronizedMeasureBase(mLogStates.back().Time, synchPreviousPoseMeas))
      {
        ExternalSensors::PoseMeasurement synchPoseMeas; // Virtual measure with synchronized timestamp and calibration applied
        if (mPoseManager->ComputeSynchronizedMeasureBase(mCurrentTime_sec, synchPoseMeas))
        {
          mTrelative = synchPreviousPoseMeas.Pose.inverse() * synchPoseMeas.Pose;
          externalAvailable = true;
          PRINT_VERBOSE(3, "Prior pose computed using external poses supplied");
        }
      }
    }
    else
      PRINT_WARNING("External poses are empty : cannot use them to compute ego motion")
  }

  // Linearly extrapolate previous motion to estimate new pose
  if (mLogStates.size() >= 2 && (
      (mEgoMotion == EgoMotionMode::MOTION_EXTRAPOLATION ||
       mEgoMotion == EgoMotionMode::MOTION_EXTRAPOLATION_AND_REGISTRATION) ||
      (mEgoMotion == EgoMotionMode::EXTERNAL_OR_MOTION_EXTRAPOLATION &&
       !externalAvailable)))
  {
    // Estimate new Tworld with a constant velocity model
    auto itSt = mLogStates.end();

    const double t1 = (--itSt)->Time;
    const Eigen::Isometry3d& T1 = itSt->Isometry;
    const double t0 = (--itSt)->Time;
    const Eigen::Isometry3d& T0 = itSt->Isometry;
    if (std::abs((mCurrentTime_sec - t1) / (t1 - t0)) > mMaxExtrapolationRatio)
      PRINT_WARNING("Unable to extrapolate scan pose from previous motion : extrapolation time is too far.")
    else
    {
      Eigen::Isometry3d nextTworldEstimation = LinearInterpolation(T0, T1, mCurrentTime_sec, t0, t1);
      mTrelative = mTworld.inverse() * nextTworldEstimation;
    }
  }

  // Refine Trelative estimation by registering current frame on previous one
  if (mEgoMotion == EgoMotionMode::REGISTRATION ||
      mEgoMotion == EgoMotionMode::MOTION_EXTRAPOLATION_AND_REGISTRATION)
  {
    // kd-tree to process fast nearest neighbor
    // among the keypoints of the previous pointcloud
    IF_VERBOSE(3, Utils::Timer::Init("EgoMotion : build KD tree"));
    std::map<Keypoint, KDTree> kdtreePrevious;
    // Kdtrees map initialization to parallelize their
    // construction using OMP and avoid concurrency issues
    for (auto k : mUsableKeypoints)
      kdtreePrevious[k] = KDTree();

    // The iteration is not directly on Keypoint types
    // because of openMP behaviour which needs int iteration on MSVC
    int nbKeypointTypes = static_cast<int>(mUsableKeypoints.size());
    #pragma omp parallel for num_threads(std::min(mNbThreads, nbKeypointTypes))
    for (int i = 0; i < nbKeypointTypes; ++i)
    {
      Keypoint k = static_cast<Keypoint>(mUsableKeypoints[i]);
      if (kdtreePrevious.count(k))
        kdtreePrevious[k].Reset(mPreviousRawKeypoints[k]);
    }

    if (mVerbosity >= 2)
    {
      std::cout << "Keypoints extracted from previous frame : ";
      for (auto k : mUsableKeypoints)
        std::cout << mPreviousRawKeypoints[k]->size() << " " << Utils::Plural(KeypointTypeNames.at(k)) << " ";
      std::cout << std::endl;
    }

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("EgoMotion : build KD tree"));
    IF_VERBOSE(3, Utils::Timer::Init("Ego-Motion : whole ICP-LM loop"));

    // Reset ICP results
    mTotalMatchedKeypoints = 0;

    // Init matching parameters
    KeypointsMatcher::Parameters matchingParams;
    matchingParams.NbThreads = mNbThreads;
    matchingParams.SingleEdgePerRing = true;
    matchingParams.MaxNeighborsDistance = mEgoMotionMaxNeighborsDistance;
    matchingParams.EdgeNbNeighbors = mEgoMotionEdgeNbNeighbors;
    matchingParams.EdgeMinNbNeighbors = mEgoMotionEdgeMinNbNeighbors;
    matchingParams.EdgeMaxModelError = mEgoMotionEdgeMaxModelError;
    matchingParams.PlaneNbNeighbors = mEgoMotionPlaneNbNeighbors;
    matchingParams.PlanarityThreshold = mEgoMotionPlanarityThreshold;
    matchingParams.PlaneMaxModelError = mEgoMotionPlaneMaxModelError;

    // ICP - Levenberg-Marquardt loop
    // At each step of this loop an ICP matching is performed. Once the keypoints
    // are matched, we estimate the the 6-DOF parameters by minimizing the
    // non-linear least square cost function using Levenberg-Marquardt algorithm.
    for (unsigned int icpIter = 0; icpIter < mEgoMotionICPMaxIter; ++icpIter)
    {
      IF_VERBOSE(3, Utils::Timer::Init("  Ego-Motion : ICP"));

      // We want to estimate our 6-DOF parameters using a non linear least square
      // minimization. The non linear part comes from the parametrization of the
      // rotation endomorphism SO(3).
      // First, we need to build the point-to-line, point-to-plane and
      // point-to-blob ICP matches that will be optimized.
      // Then, we use CERES Levenberg-Marquardt optimization to minimize the problem.

      // Create a keypoints matcher
      // At each ICP iteration, the outliers removal is refined to be stricter
      double iterRatio = icpIter / static_cast<double>(mEgoMotionICPMaxIter - 1);
      matchingParams.SaturationDistance = (1 - iterRatio) * mEgoMotionInitSaturationDistance + iterRatio * mEgoMotionFinalSaturationDistance;
      KeypointsMatcher matcher(matchingParams, mTrelative);

      // Loop over keypoints to build the residuals
      for (auto k : mUsableKeypoints)
        mEgoMotionMatchingResults[k] = matcher.BuildMatchResiduals(mCurrentRawKeypoints[k], kdtreePrevious[k], k);

      // Count matches and skip this frame
      // if there are too few geometric keypoints matched
      mTotalMatchedKeypoints = 0;
      for (auto k : mUsableKeypoints)
        mTotalMatchedKeypoints += mEgoMotionMatchingResults[k].NbMatches();

      if (mTotalMatchedKeypoints < mMinNbMatchedKeypoints)
      {
        PRINT_WARNING("Not enough keypoints, EgoMotion skipped for this frame.");
        break;
      }

      IF_VERBOSE(3, Utils::Timer::StopAndDisplay("  Ego-Motion : ICP"));
      IF_VERBOSE(3, Utils::Timer::Init("  Ego-Motion : LM optim"));

      // Init the optimizer with initial pose and parameters
      LocalOptimizer optimizer;
      optimizer.SetTwoDMode(mTwoDMode);
      optimizer.SetPosePrior(mTrelative);
      optimizer.SetLMMaxIter(mEgoMotionLMMaxIter);
      optimizer.SetNbThreads(mNbThreads);

      // Add LiDAR ICP matches
      for (auto k : mUsableKeypoints)
        optimizer.AddResiduals(mEgoMotionMatchingResults[k].Residuals);

      // Run LM optimization
      ceres::Solver::Summary summary = optimizer.Solve();
      PRINT_VERBOSE(4, summary.BriefReport());

      // Get back optimized Trelative
      mTrelative = optimizer.GetOptimizedPose();

      IF_VERBOSE(3, Utils::Timer::StopAndDisplay("  Ego-Motion : LM optim"));

      // If no L-M iteration has been made since the last ICP matching, it means
      // that we reached a local minimum for the ICP-LM algorithm.
      if (summary.num_successful_steps == 1)
      {
        break;
      }
    }

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Ego-Motion : whole ICP-LM loop"));
    if (mVerbosity >= 2)
    {
      std::cout << "Matched keypoints: " << mTotalMatchedKeypoints << " (";
      for (auto k : mUsableKeypoints)
        std::cout << mEgoMotionMatchingResults[k].NbMatches() << " " << Utils::Plural(KeypointTypeNames.at(k)) << " ";
      std::cout << ")" << std::endl;
    }
  }

  // Print EgoMotion results
  SET_COUT_FIXED_PRECISION(3);
  PRINT_VERBOSE(2, "Estimated Ego-Motion (motion since last frame):\n"
                   " translation = [" << mTrelative.translation().transpose() << "] m\n"
                   " rotation    = [" << Utils::Rad2Deg(Utils::RotationMatrixToRPY(mTrelative.linear())).transpose() << "] 째");
  RESET_COUT_FIXED_PRECISION;
}

//-----------------------------------------------------------------------------
void Slam::Localization()
{
  mLocalizationUncertainty = LocalOptimizer::RegistrationError();
  mValid = true;
  PRINT_VERBOSE(2, "========== Localization ==========");

  // Integrate the relative motion to the world transformation
  // Store previous tworld for next iteration
  mTworld = mTworld * mTrelative;

  // Init undistorted keypoints clouds from raw points
  // Warning : pointer copy = points modification :
  // do not use CurrentRawKeypoints after this step
  mCurrentUndistortedKeypoints = mCurrentRawKeypoints;
  // Init and run undistortion if required
  if (mUndistortion)
  {
    IF_VERBOSE(3, Utils::Timer::Init("Localization : initial undistortion"));
    if (mUndistortion != UndistortionMode::EXTERNAL)
    {
      // Init the within frame motion interpolator time bounds
      this->InitUndistortion();
      // Undistort keypoints clouds
      this->RefineUndistortion();
    }
    else
      this->UndistortWithPoseMeasurement();

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Localization : initial undistortion"));
  }

  // Get keypoints from maps and build kd-trees for fast nearest neighbors search
  IF_VERBOSE(3, Utils::Timer::Init("Localization : map keypoints extraction"));

  // The iteration is not directly on Keypoint types
  // because of openMP behaviour which needs int iteration on MSVC
  int nbKeypointTypes = static_cast<int>(mUsableKeypoints.size());
  #pragma omp parallel for num_threads(std::min(mNbThreads, nbKeypointTypes))
  for (int i = 0; i < nbKeypointTypes; ++i)
  {
    Keypoint k = static_cast<Keypoint>(mUsableKeypoints[i]);
    // Check the current frame contains not null number of k type keypoints
    if (mCurrentUndistortedKeypoints[k] && mCurrentUndistortedKeypoints[k]->empty())
      continue;
    // If the map has been updated, the KD-tree needs to be updated
    if (!mLocalMaps[k]->IsSubMapKdTreeValid())
    {
      // If maps are fixed, we can build a single KD-tree
      // of the entire map to avoid rebuilding it again
      if (mMapUpdate == MappingMode::NONE)
        mLocalMaps[k]->BuildSubMapKdTree();

      // Otherwise, we only extract the local sub maps
      // to build a local and smaller KD-tree
      else
      {
        if (mLocalMaps[k]->IsTimeThreshold())
        {
          IF_VERBOSE(3, Utils::Timer::Init("Localization : clearing old points"));
          mLocalMaps[k]->ClearOldPoints(mCurrentTime_sec);
          IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Localization : clearing old points"));
        }
        // Estimate current keypoints bounding box
        PointCloud currWorldKeypoints;
        pcl::transformPointCloud(*mCurrentUndistortedKeypoints[k], currWorldKeypoints, mTworld.matrix());
        Eigen::Vector4f minPoint, maxPoint;
        pcl::getMinMax3D(currWorldKeypoints, minPoint, maxPoint);

        // Build submap of all points lying in this bounding box
        // Moving objects are rejected but the constraint is removed
        // if less than half the number of current keypoints are extracted from the map
        mLocalMaps[k]->BuildSubMapKdTree(minPoint.head<3>().array(), maxPoint.head<3>().array(), currWorldKeypoints.size() / 2);
      }
    }
  }

  if (mVerbosity >= 2)
  {
    std::cout << "Keypoints extracted from map : ";
    for (auto k : mUsableKeypoints)
    {
      std::cout << mLocalMaps[k]->GetSubMapKdTree().GetInputCloud()->size()
                << " " << Utils::Plural(KeypointTypeNames.at(k)) << " ";
    }
    std::cout << std::endl;
  }

  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Localization : map keypoints extraction"));
  IF_VERBOSE(3, Utils::Timer::Init("Localization : whole ICP-LM loop"));

  // Reset ICP results
  mTotalMatchedKeypoints = 0;

  // Init matching parameters
  KeypointsMatcher::Parameters matchingParams;
  matchingParams.NbThreads = mNbThreads;
  matchingParams.SingleEdgePerRing = false;
  matchingParams.MaxNeighborsDistance = mLocalizationMaxNeighborsDistance;
  matchingParams.EdgeNbNeighbors = mLocalizationEdgeNbNeighbors;
  matchingParams.EdgeMinNbNeighbors = mLocalizationEdgeMinNbNeighbors;
  matchingParams.EdgeMaxModelError = mLocalizationEdgeMaxModelError;
  matchingParams.PlaneNbNeighbors = mLocalizationPlaneNbNeighbors;
  matchingParams.PlanarityThreshold = mLocalizationPlanarityThreshold;
  matchingParams.PlaneMaxModelError = mLocalizationPlaneMaxModelError;
  matchingParams.BlobNbNeighbors = mLocalizationBlobNbNeighbors;

  // ICP - Levenberg-Marquardt loop
  // At each step of this loop an ICP matching is performed. Once the keypoints
  // are matched, we estimate the the 6-DOF parameters by minimizing the
  // non-linear least square cost function using Levenberg-Marquardt algorithm.
  for (unsigned int icpIter = 0; icpIter < mLocalizationICPMaxIter; ++icpIter)
  {
    IF_VERBOSE(3, Utils::Timer::Init("  Localization : ICP"));

    // We want to estimate our 6-DOF parameters using a non linear least square
    // minimization. The non linear part comes from the parametrization of the
    // rotation endomorphism SO(3).
    // First, we need to build the point-to-line, point-to-plane and
    // point-to-blob ICP matches that will be optimized.
    // Then, we use CERES Levenberg-Marquardt optimization to minimize problem.

    // Create a keypoints matcher
    // At each ICP iteration, the outliers removal is refined to be stricter
    double iterRatio = icpIter / static_cast<double>(mLocalizationICPMaxIter - 1);
    matchingParams.SaturationDistance = (1 - iterRatio) * mLocalizationInitSaturationDistance + iterRatio * mLocalizationFinalSaturationDistance;
    KeypointsMatcher matcher(matchingParams, mTworld);

    // Loop over keypoints to build the point to line residuals
    mTotalMatchedKeypoints = 0;
    for (auto k : mUsableKeypoints)
    {
      mLocalizationMatchingResults[k] = matcher.BuildMatchResiduals(mCurrentUndistortedKeypoints[k], mLocalMaps[k]->GetSubMapKdTree(), k);
      mTotalMatchedKeypoints += mLocalizationMatchingResults[k].NbMatches();
    }

    // Skip frame if not enough keypoints are extracted
    if (mTotalMatchedKeypoints < mMinNbMatchedKeypoints)
    {
      // Reset state to previous one to avoid instability
      if (mLogStates.empty())
        mTworld = mTworldInit;
      else
        mTworld = mLogStates.back().Isometry;
      if (mUndistortion)
        mWithinFrameMotion.SetTransforms(Eigen::Isometry3d::Identity(), Eigen::Isometry3d::Identity());
      PRINT_ERROR("Not enough keypoints matched, Localization skipped for this frame.");
      mValid = false;
      break;
    }

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("  Localization : ICP"));
    IF_VERBOSE(3, Utils::Timer::Init("  Localization : LM optim"));

    // Init the optimizer with initial pose and parameters
    LocalOptimizer optimizer;
    optimizer.SetTwoDMode(mTwoDMode);
    optimizer.SetPosePrior(mTworld);
    optimizer.SetLMMaxIter(mLocalizationLMMaxIter);
    optimizer.SetNbThreads(mNbThreads);

    // Add LiDAR ICP matches
    for (auto k : mUsableKeypoints)
      optimizer.AddResiduals(mLocalizationMatchingResults[k].Residuals);

    // Add odometry constraint
    // if constraint has been successfully created
    if (mWheelOdomManager && mWheelOdomManager->GetResidual().Cost)
      optimizer.AddResidual(mWheelOdomManager->GetResidual());

    // Add gravity alignment constraint
    // if constraint has been successfully created
    if (mGravityManager && mGravityManager->GetResidual().Cost)
      optimizer.AddResidual(mGravityManager->GetResidual());

    // Add Pose constraint
    // if constraint has been successfully created
    if (mPoseManager && mPoseManager->GetResidual().Cost)
      optimizer.AddResidual(mPoseManager->GetResidual());

    // Add available landmark constraints
    for (auto& idLm : mLandmarksManagers)
    {
      // Add landmark constraint
      // if constraint has been successfully created
      if (idLm.second.GetResidual().Cost)
        optimizer.AddResidual(idLm.second.GetResidual());
    }

    // Run LM optimization
    ceres::Solver::Summary summary = optimizer.Solve();
    PRINT_VERBOSE(4, summary.BriefReport());

    // Update Tworld from optimization results
    mTworld = optimizer.GetOptimizedPose();

    // Optionally refine undistortion
    if (mUndistortion == UndistortionMode::REFINED)
      this->RefineUndistortion();

    IF_VERBOSE(3, Utils::Timer::StopAndDisplay("  Localization : LM optim"));

    // If no L-M iteration has been made since the last ICP matching, it means
    // that we reached a local minimum for the ICP-LM algorithm.
    // We evaluate the quality of the Tworld optimization using an approximate
    // computation of the variance covariance matrix.
    if ((summary.num_successful_steps == 1) || (icpIter == mLocalizationICPMaxIter - 1))
    {
      mLocalizationUncertainty = optimizer.EstimateRegistrationError();
      break;
    }
  }

  IF_VERBOSE(3, Utils::Timer::StopAndDisplay("Localization : whole ICP-LM loop"));

  // Optionally print localization optimization summary
  if (mVerbosity >= 2)
  {
    SET_COUT_FIXED_PRECISION(3);
    std::cout << "Matched keypoints: " << mTotalMatchedKeypoints << " (";
    for (auto k : mUsableKeypoints)
      std::cout << mLocalizationMatchingResults[k].NbMatches() << " " << Utils::Plural(KeypointTypeNames.at(k)) << " ";

    std::cout << ")"
              << "\nPosition uncertainty    = " << mLocalizationUncertainty.PositionError    << " m"
              << " (along [" << mLocalizationUncertainty.PositionErrorDirection.transpose()    << "])"
              << "\nOrientation uncertainty = " << mLocalizationUncertainty.OrientationError << " 째"
              << " (along [" << mLocalizationUncertainty.OrientationErrorDirection.transpose() << "])"
              << std::endl;
    RESET_COUT_FIXED_PRECISION;
  }
}

//-----------------------------------------------------------------------------
bool Slam::CheckKeyFrame()
{
  // Compute motion since last keyframe
  Eigen::Isometry3d motionSinceLastKf = mKfLastPose.inverse() * mTworld;
  double transSinceLastKf = motionSinceLastKf.translation().norm();
  double rotSinceLastKf = Eigen::AngleAxisd(motionSinceLastKf.linear()).angle();
  PRINT_VERBOSE(3, "Motion since last keyframe #" << mKfCounter << ": "
                                                  << transSinceLastKf << " m, "
                                                  << Utils::Rad2Deg(rotSinceLastKf) << " 째");
  // Check if current frame is a new keyframe
  // If we don't have enough keyframes yet, the threshold is linearly lowered
  constexpr double MIN_KF_NB = 10.;
  double thresholdCoef = std::min(mKfCounter / MIN_KF_NB, 1.);
  unsigned int nbMapKpts = 0;
  for (const auto& mapKptsCloud : mLocalMaps)
    nbMapKpts += mapKptsCloud.second->Size();

  // Mark as keyframe if a new tag was seen after some time
  // This allows to force some keyframes and therefore a constraint in the pose graph optimization
  // if the tag detections are quite sparse
  bool tagRequirement = false;
  for (auto& idLm : mLandmarksManagers)
  {
    if (idLm.second.NeedsReferencePoseRefresh(mCurrentTime_sec))
    {
      tagRequirement = true;
      break;
    }
  }

  return nbMapKpts < mMinNbMatchedKeypoints * 10 ||
         transSinceLastKf >= thresholdCoef * mKfDistanceThreshold ||
         rotSinceLastKf >= Utils::Deg2Rad(thresholdCoef * mKfAngleThreshold) ||
         tagRequirement;
}

//-----------------------------------------------------------------------------
void Slam::UpdateMapsUsingTworld()
{
  PRINT_VERBOSE(3, "Adding new keyframe #" << mKfCounter);

  // Transform keypoints to WORLD coordinates
  for (auto k : mUsableKeypoints)
    mCurrentWorldKeypoints[k] = this->GetKeypoints(k, true);

  // Add registered points to map
  // The iteration is not directly on Keypoint types
  // because of openMP behaviour which needs int iteration on MSVC
  int nbKeypointTypes = static_cast<int>(mUsableKeypoints.size());
  #pragma omp parallel for num_threads(std::min(mNbThreads, nbKeypointTypes))
  for (int i = 0; i < nbKeypointTypes; ++i)
  {
    Keypoint k = static_cast<Keypoint>(mUsableKeypoints[i]);
    // Add not fixed points
    mLocalMaps[k]->Add(mCurrentWorldKeypoints[k], false);
  }
}

//-----------------------------------------------------------------------------
void Slam::LogCurrentFrameState()
{
  // The two last poses are logged in any case for motion extrapolation and undistortion
  // So, if LogOnlyKeyframes is required, remove the second last pose at each iteration if it was not a keyframe
  if (mLogStates.size() > 1)
  {
    auto itSt = mLogStates.end();
    --itSt; --itSt;
    if (mLogOnlyKeyframes && !itSt->IsKeyFrame)
      mLogStates.erase(itSt);
  }
  // Save current state to log buffer.
  // This buffer will be processed in the pose graph optimization
  // and is used locally to compute prior ego-motion estimation
  // and to undistort the input points
  LidarState state;
  state.Isometry = mTworld;
  // Increase covariance area by scale
  state.Covariance = std::pow(mCovarianceScale, 2) * mLocalizationUncertainty.Covariance;
  float defaultPositionError = 1e-2; // 1cm
  float defaultAngleError = Utils::Deg2Rad(1.f); // 1째
  if (!Utils::isCovarianceValid(state.Covariance))
    state.Covariance = Utils::CreateDefaultCovariance(defaultPositionError, defaultAngleError); //1mm, 0.5째

  // If 2D mode enabled, supply constant covariance for unevaluated variables
  if (mTwoDMode)
  {
    state.Covariance(2, 2) = std::pow(defaultPositionError, 2);
    state.Covariance(3, 3) = std::pow(defaultAngleError,    2);
    state.Covariance(4, 4) = std::pow(defaultAngleError,    2);
  }
  state.Time = mCurrentTime_sec;
  state.Index = mNbrFrameProcessed;
  state.IsKeyFrame = mIsKeyFrame;
  for (auto k : mUsableKeypoints)
    state.Keypoints[k] = std::make_shared<PCStorage>(mCurrentUndistortedKeypoints[k], mLoggingStorage);

  mLogStates.emplace_back(state);
  // Remove the oldest logged states
  auto itSt = mLogStates.begin();
  while (mCurrentTime_sec - itSt->Time > mLoggingTimeout && mLogStates.size() > 2)
  {
    ++itSt;
    mLogStates.pop_front();
  }
}

//-----------------------------------------------------------------------------
LidarState& Slam::GetLastState()
{
  return mLogStates.back();
}

//==============================================================================
//   Undistortion helpers
//==============================================================================

//-----------------------------------------------------------------------------
Eigen::Isometry3d Slam::InterpolateScanPose(double time)
{
  if (mLogStates.empty())
    return mTworld;

  const double prevPoseTime = mLogStates.back().Time;
  if (std::abs(time / (mCurrentTime_sec - prevPoseTime)) > mMaxExtrapolationRatio)
  {
    PRINT_WARNING("Unable to interpolate scan pose from motion : extrapolation time is too far.");
    return mTworld;
  }

  return LinearInterpolation(mLogStates.back().Isometry, mTworld, mCurrentTime_sec + time, prevPoseTime, mCurrentTime_sec);
}

//-----------------------------------------------------------------------------
void Slam::InitUndistortion()
{
  // Get 'time' field range
  double frameFirstTime = std::numeric_limits<double>::max();
  double frameLastTime  = std::numeric_limits<double>::lowest();
  for (auto k : mUsableKeypoints)
  {
    for (const auto& point : *mCurrentUndistortedKeypoints[k])
    {
      frameFirstTime = std::min(frameFirstTime, point.time);
      frameLastTime  = std::max(frameLastTime, point.time);
    }
  }

  // Update interpolator timestamps and reset transforms
  mWithinFrameMotion.SetTimes(frameFirstTime, frameLastTime);
  mWithinFrameMotion.SetTransforms(Eigen::Isometry3d::Identity(), Eigen::Isometry3d::Identity());

  // Check time values
  if (mWithinFrameMotion.GetTimeRange() < 1e-6)
  {
    // If frame duration is 0, it means that the time field is constant and cannot be used.
    // We reset timestamps to 0, to ensure no time offset will be used.
    PRINT_WARNING("'time' field is not properly set (constant value) and cannot be used for undistortion.");
    mWithinFrameMotion.SetTimes(0., 0.);
  }
  else if (mWithinFrameMotion.GetTimeRange() > 10.)
  {
    // If frame duration is bigger than 10 seconds, it is probably wrongly set
    PRINT_WARNING("'time' field looks not properly set (frame duration > 10 s) and can lead to faulty undistortion.");
  }
}

//-----------------------------------------------------------------------------
void Slam::UndistortWithPoseMeasurement()
{
  if (this->PoseHasData())
  {
    // Get synchronized point pose relatively to frame
    ExternalSensors::PoseMeasurement synchPoseMeasCurrent; // Virtual measure with synchronized timestamp and calibration applied
    if (mPoseManager->ComputeSynchronizedMeasureBase(mCurrentTime_sec, synchPoseMeasCurrent))
    {
      Eigen::Isometry3d invSynchPoseMeasCurrent = synchPoseMeasCurrent.Pose.inverse();
      // Undistort keypoints
      for (auto k : mUsableKeypoints)
      {
        // Compute synchronized measures (not parallelizable)
        int nbPoints = mCurrentUndistortedKeypoints[k]->size();
        std::vector<ExternalSensors::PoseMeasurement> synchMeas (nbPoints); // Virtual measures with synchronized timestamp and calibration applied
        // Sort points by time to speed up synchronization search
        std::sort(mCurrentUndistortedKeypoints[k]->points.begin(), mCurrentUndistortedKeypoints[k]->points.end(), [](const LidarPoint& pt1, const LidarPoint& pt2){return pt1.time < pt2.time;});
        int idxPt = 0;
        for (auto& point : *mCurrentUndistortedKeypoints[k])
        {
          mPoseManager->ComputeSynchronizedMeasureBase(mCurrentTime_sec + point.time, synchMeas[idxPt]);
          ++idxPt;
        }

        // Transform with computed measures (parallelized)
        #pragma omp parallel for num_threads(mNbThreads)
        for (int i = 0; i < nbPoints; ++i)
        {
          auto& point = mCurrentUndistortedKeypoints[k]->at(i);
          Utils::TransformPoint(point, invSynchPoseMeasCurrent * synchMeas[i].Pose);
        }
      }
    }
  }
  else
    PRINT_WARNING("External poses are empty : cannot use them to undistort input pointcloud")
}

//-----------------------------------------------------------------------------
void Slam::RefineUndistortion()
{
  // Get previously applied undistortion
  Eigen::Isometry3d previousBaseBegin = mWithinFrameMotion.GetH0();
  Eigen::Isometry3d previousBaseEnd = mWithinFrameMotion.GetH1();

  // Extrapolate first and last poses to update within frame motion interpolator
  Eigen::Isometry3d worldToBaseBegin = this->InterpolateScanPose(mWithinFrameMotion.GetTime0());
  Eigen::Isometry3d worldToBaseEnd = this->InterpolateScanPose(mWithinFrameMotion.GetTime1());
  Eigen::Isometry3d baseToWorld = mTworld.inverse();
  Eigen::Isometry3d newBaseBegin = baseToWorld * worldToBaseBegin;
  Eigen::Isometry3d newBaseEnd = baseToWorld * worldToBaseEnd;
  mWithinFrameMotion.SetTransforms(newBaseBegin, newBaseEnd);

  // Init the interpolator to use to remove previous undistortion and apply updated one
  auto transformInterpolator = mWithinFrameMotion;
  transformInterpolator.SetTransforms(newBaseBegin * previousBaseBegin.inverse(),
                                      newBaseEnd   * previousBaseEnd.inverse());

  // Refine undistortion of keypoints clouds
  for (auto k : mUsableKeypoints)
  {
    int nbPoints = mCurrentUndistortedKeypoints[k]->size();
    #pragma omp parallel for num_threads(mNbThreads)
    for (int i = 0; i < nbPoints; ++i)
    {
      auto& point = mCurrentUndistortedKeypoints[k]->at(i);
      Utils::TransformPoint(point, transformInterpolator(point.time));
    }
  }
}

//==============================================================================
//   Confidence estimators
//==============================================================================

//-----------------------------------------------------------------------------
void Slam::SetOverlapSamplingRatio (float _arg)
{
  // Clamp ratio beteen 0 and 1
  mOverlapSamplingRatio = Utils::Clamp(_arg, 0.f, 1.f);

  // Reset overlap value if overlap computation is disabled
  if (mOverlapSamplingRatio == 0.)
    mOverlapEstimation = -1.f;
}

//-----------------------------------------------------------------------------
void Slam::EstimateOverlap()
{
  // Aggregate all input points into WORLD coordinates
  PointCloud::Ptr aggregatedPoints = this->GetRegisteredFrame();

  // Keep only the maps to use
  std::map<Keypoint, std::shared_ptr<RollingGrid>> mapsToUse;
  for (auto k : mUsableKeypoints)
  {
    if (mLocalMaps[k]->IsSubMapKdTreeValid())
      mapsToUse[k] = mLocalMaps[k];
  }

  // Compute LCP like estimator
  // (see http://geometry.cs.ucl.ac.uk/projects/2014/super4PCS/ for more info)
  mOverlapEstimation = Confidence::LCPEstimator(aggregatedPoints, mapsToUse, mOverlapSamplingRatio, mNbThreads);
  PRINT_VERBOSE(3, "Overlap : " << mOverlapEstimation << ", estimated on : "
                                << static_cast<int>(aggregatedPoints->size() * mOverlapSamplingRatio) << " points.");
}

//-----------------------------------------------------------------------------
void Slam::CheckMotionLimits()
{
    int nPoses = mLogStates.size();
    if (nPoses == 0)
        return;

    // Extract number of poses to comply with the required window time, and relative time duration.
    double deltaTime_sec = mCurrentTime_sec - mLogStates.back().Time;
    double nextDeltaTime = FLT_MAX;

    // Index of the last pose that defines the window starting bound
    // The window ends on current pose
    auto startIt = mLogStates.end();
    auto beforeBegin = mLogStates.begin();
    --beforeBegin;
    --startIt;

    // If the time between current pose and the last pose is l.t. TimeWindowDuration, look for the window's starting bound pose
    if (deltaTime_sec < mTimeWindowDuration)
    {
        // Search an interval containing TimeWindowDuration : [deltaTime, nextDeltaTime]
        while (startIt != beforeBegin)
        {
            deltaTime_sec = nextDeltaTime;
            nextDeltaTime = mCurrentTime_sec - startIt->Time;
            if (nextDeltaTime >= mTimeWindowDuration)
                break;
            --startIt;
        }

        // If startIt lays before first element, no interval containing TimeWindowDuration was found, the oldest logged pose is taken
        if (startIt == beforeBegin)
        {
            PRINT_WARNING("Not enough logged trajectory poses to get the required time window to estimate velocity, using a smaller time window of "
                        << nextDeltaTime << "s")
            startIt = mLogStates.begin();
        }

        // Choose which bound of the interval is the best window's starting bound
        else if (std::abs(deltaTime_sec - mTimeWindowDuration) < std::abs(nextDeltaTime - mTimeWindowDuration))
            ++startIt;

        // Actualize deltaTime with the best startIndex
        deltaTime_sec = mCurrentTime_sec - startIt->Time;
    }

    // If the time between current pose and the last pose is g.t. TimeWindowDuration, take the last pose as window's starting bound
    else
        PRINT_WARNING("The required time window is too short to estimate velocity, using motion since last pose")

    mComplyMotionLimits = true;

    // Compute transform between the two pose bounds of the window
    Eigen::Isometry3d TWindow = startIt->Isometry.inverse() * mTworld;

    // Compute angular part
    // NOTE : It is not possible to detect an angle greater than PI,
    // the detectable velocity and acceleration are limited on deltaTime
    // Rotation angle in [0, 2pi]
    float angle = Eigen::AngleAxisd(TWindow.linear()).angle();

    // Rotation angle in [0, pi]
    if (angle > M_PI)
        angle = 2 * M_PI - angle;

    angle = Utils::Rad2Deg(angle);

    // Compute linear part
    float distance = TWindow.translation().norm();

    // Compute velocity
    Eigen::Array2f velocity = {distance / deltaTime_sec, angle / deltaTime_sec};
    SET_COUT_FIXED_PRECISION(3);

    // Print local velocity
    PRINT_VERBOSE(3, "Velocity     = " << std::setw(6) << velocity[0] << " m/s,  "
                                        << std::setw(6) << velocity[1] << " 째/s")
    RESET_COUT_FIXED_PRECISION;

    if (mNbrFrameProcessed >= 2)
    {
        // Compute local acceleration in BASE
        Eigen::Array2f acceleration = (velocity - mPreviousVelocity) / deltaTime_sec;

        // Print local acceleration
        SET_COUT_FIXED_PRECISION(3);
        PRINT_VERBOSE(3, "Acceleration = " << std::setw(6) << acceleration[0] << " m/s2, "
                                            << std::setw(6) << acceleration[1] << " 째/s2")
        RESET_COUT_FIXED_PRECISION;

        // Check velocity compliance
        bool complyVelocityLimits = (velocity < mVelocityLimits).all();

        // Check acceleration compliance
        bool complyAccelerationLimits = (acceleration.abs() < mAccelerationLimits).all();

        // Set ComplyMotionLimits
        mComplyMotionLimits = complyVelocityLimits && complyAccelerationLimits;
    }

    mPreviousVelocity = velocity;

    if (!mComplyMotionLimits)
        PRINT_WARNING("The pose does not comply with the motion limitations. Lidar SLAM may have failed.")
}

//==============================================================================
//   Transformation helpers
//==============================================================================

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::TransformPointCloud(PointCloud::ConstPtr cloud,
                                                const Eigen::Isometry3d& tf,
                                                const std::string& frameId) const
{
  // Copy all fields and set frame ID
  PointCloud::Ptr transformedCloud(new PointCloud);
  pcl::copyPointCloud(*cloud, *transformedCloud);
  transformedCloud->header.frame_id = frameId;

  // Transform each point inplace in parallel
  int nbPoints = transformedCloud->size();
  #pragma omp parallel for num_threads(mNbThreads)
  for (int i = 0; i < nbPoints; ++i)
  {
    auto& point = transformedCloud->at(i);
    Utils::TransformPoint(point, tf);
  }
  return transformedCloud;
}

//-----------------------------------------------------------------------------
Slam::PointCloud::Ptr Slam::AggregateFrames(const std::vector<PointCloud::Ptr>& frames, bool worldCoordinates) const
{
  PointCloud::Ptr aggregatedFrames(new PointCloud);
  aggregatedFrames->header = Utils::BuildPclHeader(mCurrentFrames[0]->header.stamp,
                                                   worldCoordinates ? mWorldFrameId : mBaseFrameId,
                                                   mNbrFrameProcessed);

  // Loop over frames of input
  for (const auto& frame: frames)
  {
    // If the frame is empty, ignore it
    if (frame->empty())
      continue;

    // Add frame to aggregated output
    int startIdx = aggregatedFrames->size();
    int endIdx = startIdx + frame->size();
    *aggregatedFrames += *frame;

    // Modify point-wise time offsets to match header.stamp
    // And transform points from LIDAR to BASE or WORLD coordinate system
    double timeOffset = Utils::PclStampToSec(frame->header.stamp) - Utils::PclStampToSec(aggregatedFrames->header.stamp);
    Eigen::Isometry3d baseToLidar = this->GetBaseToLidarOffset(frame->front().device_id);

    // Rigid transform from LIDAR to BASE then undistortion from BASE to WORLD
    if (worldCoordinates && mUndistortion)
    {
      auto transformInterpolator = mWithinFrameMotion;
      transformInterpolator.SetTransforms(mTworld * mWithinFrameMotion.GetH0() * baseToLidar,
                                          mTworld * mWithinFrameMotion.GetH1() * baseToLidar);
      #pragma omp parallel for num_threads(mNbThreads)
      for (int i = startIdx; i < endIdx; ++i)
      {
        auto& point = aggregatedFrames->at(i);
        point.time += timeOffset;
        Utils::TransformPoint(point, transformInterpolator(point.time));
      }
    }

    // Rigid transform from LIDAR to BASE or WORLD coordinate system
    else
    {
      // Get rigid transform to apply
      Eigen::Isometry3d tf = worldCoordinates ? mTworld * baseToLidar : baseToLidar;
      // If transform to apply is identity, avoid much work
      if (tf.isApprox(Eigen::Isometry3d::Identity()))
      {
        #pragma omp parallel for num_threads(mNbThreads)
        for (int i = startIdx; i < endIdx; ++i)
          aggregatedFrames->at(i).time += timeOffset;
      }
      // If transform is non trivial, run transformation
      else
      {
        #pragma omp parallel for num_threads(mNbThreads)
        for (int i = startIdx; i < endIdx; ++i)
        {
          auto& point = aggregatedFrames->at(i);
          point.time += timeOffset;
          Utils::TransformPoint(point, tf);
        }
      }
    }
  }

  return aggregatedFrames;
}

//==============================================================================
//   External sensors
//==============================================================================

//-----------------------------------------------------------------------------
void Slam::InitWheelOdom()
{
  mWheelOdomManager = std::make_shared<ExternalSensors::WheelOdometryManager>(0.,
                                                                                   mSensorTimeOffset,
                                                                                   mSensorTimeThreshold,
                                                                                   mSensorMaxMeasures,
                                                                                   mVerbosity >= 3);
}

//-----------------------------------------------------------------------------
void Slam::InitGravity()
{
  mGravityManager = std::make_shared<ExternalSensors::ImuGravityManager>(0.,
                                                                              mSensorTimeOffset,
                                                                              mSensorTimeThreshold,
                                                                              mSensorMaxMeasures,
                                                                              mVerbosity >= 3);
}

//-----------------------------------------------------------------------------
void Slam::InitLandmarkManager(int id)
{
  mLandmarksManagers[id] = ExternalSensors::LandmarkManager(mSensorTimeOffset,
                                                                 mSensorTimeThreshold,
                                                                 mSensorMaxMeasures,
                                                                 mLandmarkPositionOnly,
                                                                 mVerbosity >= 3);
  mLandmarksManagers[id].SetWeight(mLandmarkWeight);
  mLandmarksManagers[id].SetSaturationDistance(mLandmarkSaturationDistance);
  // The calibration can be modified afterwards
  mLandmarksManagers[id].SetCalibration(mLmDetectorCalibration);
}

//-----------------------------------------------------------------------------
void Slam::InitGps()
{
  mGpsManager = std::make_shared<ExternalSensors::GpsManager>(mSensorTimeOffset,
                                                                   mSensorTimeThreshold,
                                                                   mSensorMaxMeasures,
                                                                   mVerbosity >= 3);
}

//-----------------------------------------------------------------------------
void Slam::InitPoseSensor()
{
  mPoseManager = std::make_shared<ExternalSensors::PoseManager>(0.,
                                                                     mSensorTimeOffset,
                                                                     mSensorTimeThreshold,
                                                                     mSensorMaxMeasures,
                                                                     mVerbosity >= 3);
}

// Sensor data
//-----------------------------------------------------------------------------

// Wheel odometer
//-----------------------------------------------------------------------------
void Slam::AddWheelOdomMeasurement(const ExternalSensors::WheelOdomMeasurement& om)
{
  if (!mWheelOdomManager)
    this->InitWheelOdom();
  mWheelOdomManager->AddMeasurement(om);
}

// IMU gravity
//-----------------------------------------------------------------------------
void Slam::AddGravityMeasurement(const ExternalSensors::GravityMeasurement& gm)
{
  if (!mGravityManager)
    this->InitGravity();
  mGravityManager->AddMeasurement(gm);
}

// Landmark detector
//-----------------------------------------------------------------------------
void Slam::AddLandmarkMeasurement(const ExternalSensors::LandmarkMeasurement& lm, int id)
{
  if (!mLandmarksManagers.count(id))
    this->InitLandmarkManager(id);
  mLandmarksManagers[id].AddMeasurement(lm);
}

//-----------------------------------------------------------------------------
void Slam::AddLandmarkManager(int id, const Eigen::Vector6d& absolutePose, const Eigen::Matrix6d& absolutePoseCovariance)
{
  if (!mLandmarksManagers.count(id))
    this->InitLandmarkManager(id);
  mLandmarksManagers[id].SetAbsolutePose(absolutePose, absolutePoseCovariance);
}

//-----------------------------------------------------------------------------
void Slam::SetLmDetectorCalibration(const Eigen::Isometry3d& calib)
{
  mLmDetectorCalibration = calib;
  for (auto& idLm : mLandmarksManagers)
    idLm.second.SetCalibration(calib);
}

//-----------------------------------------------------------------------------
bool Slam::LmCanBeUsedLocally()
{
  bool lmCanBeUsed = false;
  for (auto& idLm : mLandmarksManagers)
  {
    if (idLm.second.CanBeUsedLocally())
    {
      lmCanBeUsed = true;
      break;
    }
  }
  return lmCanBeUsed;
}

//-----------------------------------------------------------------------------
bool Slam::LmHasData()
{
  bool lmHasData = false;
  for (auto& idLm : mLandmarksManagers)
  {
    if (idLm.second.HasData())
    {
      lmHasData = true;
      break;
    }
  }
  return lmHasData;
}

// GPS
//-----------------------------------------------------------------------------
void Slam::AddGpsMeasurement(const ExternalSensors::GpsMeasurement& gpsMeas)
{
  if (!mGpsManager)
    this->InitGps();
  mGpsManager->AddMeasurement(gpsMeas);
}

//-----------------------------------------------------------------------------
void Slam::SetGpsCalibration(const Eigen::Isometry3d& calib)
{
  if (!mGpsManager)
    this->InitGps();
  mGpsManager->SetCalibration(calib);
}

//-----------------------------------------------------------------------------
Eigen::Isometry3d Slam::GetGpsCalibration()
{
  if (!mGpsManager)
  {
    PRINT_ERROR("Cannot get GPS calibration : GPS not enabled")
    return Eigen::Isometry3d::Identity();
  }
  return mGpsManager->GetCalibration();
}

//-----------------------------------------------------------------------------
Eigen::Isometry3d Slam::GetGpsOffset()
{
  if (!mGpsManager)
  {
    PRINT_ERROR("Cannot get GPS offset : GPS not enabled")
    return Eigen::Isometry3d::Identity();
  }
  return mGpsManager->GetOffset();
}

//-----------------------------------------------------------------------------
bool Slam::CalibrateWithGps()
{
  if (!this->GpsHasData())
  {
    PRINT_ERROR("Cannot get GPS offset : GPS not enabled or GPS data not available")
    return false;
  }

  // The search for a synchronized data is one-time so we
  // don't want to keep track of time for next searches (see ComputeSynchronizedMeasure)
  bool trackTime = false;

  // Initialize GPS offset with first synchronized measurements
  // The first graph optimizations will mainly correct the orientations
  Eigen::Isometry3d offset = Eigen::Isometry3d::Identity();
  for (auto& s : mLogStates)
  {
    ExternalSensors::GpsMeasurement gpsSynchMeasure; // Virtual measure with synchronized timestamp and no offset applied
    if (mGpsManager->ComputeSynchronizedMeasure(s.Time, gpsSynchMeasure, trackTime))
    {
      offset.translation() = (s.Isometry * mGpsManager->GetCalibration()).translation() - gpsSynchMeasure.Position;
      break;
    }
  }
  mGpsManager->SetOffset(offset);

  // Optimize the graph : add lidar states and link with fixed gps states
  if (!this->OptimizeGraph())
    return false;

  // Reset poses in odom frame (first Lidar pose)
  Eigen::Isometry3d firstInverse = mLogStates.front().Isometry.inverse();
  for (auto& s : mLogStates)
  {
    // Rotate covariance
    Eigen::Vector6d initPose = Utils::IsometryToXYZRPY(s.Isometry);
    CeresTools::RotateCovariance(initPose, s.Covariance, firstInverse, true); // new = first^-1 * init
    // Transform pose
    s.Isometry = firstInverse * s.Isometry;
  }

  // Update the maps and the pose with new trajectory
  this->UpdateMaps();
  this->SetWorldTransformFromGuess(mLogStates.back().Isometry);

  // Set refined offset : first Lidar pose + initial offset
  firstInverse.translation() += offset.translation();
  mGpsManager->SetOffset(firstInverse);

  return true;
}

// Pose
//-----------------------------------------------------------------------------
void Slam::AddPoseMeasurement(const ExternalSensors::PoseMeasurement& pm)
{
  if (!mPoseManager)
    this->InitPoseSensor();
  mPoseManager->AddMeasurement(pm);
}

//-----------------------------------------------------------------------------
void Slam::SetPoseCalibration(const Eigen::Isometry3d& calib)
{
  if (!mPoseManager)
    this->InitPoseSensor();
  mPoseManager->SetCalibration(calib);
}

// Sensors' parameters
//-----------------------------------------------------------------------------

#define ExtSensorMacro(inFuncProto) \
{ \
  if (mWheelOdomManager) \
    mWheelOdomManager->inFuncProto; \
  if (mGravityManager) \
    mGravityManager->inFuncProto; \
  for (auto& idLm : mLandmarksManagers) \
    idLm.second.inFuncProto; \
  if (mGpsManager) \
    mGpsManager->inFuncProto; \
  if (mPoseManager) \
    mPoseManager->inFuncProto; \
}

//-----------------------------------------------------------------------------
void Slam::ResetSensors(bool emptyMeasurements)
{
  ExtSensorMacro(Reset(emptyMeasurements))
}

//-----------------------------------------------------------------------------
void Slam::SetSensorTimeOffset(double timeOffset)
{
  ExtSensorMacro(SetTimeOffset(timeOffset))
  mSensorTimeOffset = timeOffset;
}

//-----------------------------------------------------------------------------
void Slam::SetSensorTimeThreshold(double thresh)
{
  ExtSensorMacro(SetTimeThreshold(thresh))
  mSensorTimeThreshold = thresh;
}

//-----------------------------------------------------------------------------
void Slam::SetSensorMaxMeasures(unsigned int max)
{
  ExtSensorMacro(SetMaxMeasures(max))
  mSensorMaxMeasures = max;
}

// Wheel odometer
//-----------------------------------------------------------------------------
double Slam::GetWheelOdomWeight() const
{
  if(mWheelOdomManager)
    return mWheelOdomManager->GetWeight();
  PRINT_ERROR("Wheel odometer has not been set : can't get wheel odom weight")
  return 0.;
}

//-----------------------------------------------------------------------------
void Slam::SetWheelOdomWeight(double weight)
{
  if(!mWheelOdomManager)
    this->InitWheelOdom();
  mWheelOdomManager->SetWeight(weight);
}

//-----------------------------------------------------------------------------
bool Slam::GetWheelOdomRelative() const
{
  if(mWheelOdomManager)
    return mWheelOdomManager->GetRelative();
  PRINT_ERROR("Wheel odometer has not been set : can't get wheel odom relative boolean")
  return false;
}

//-----------------------------------------------------------------------------
void Slam::SetWheelOdomRelative(bool isRelative)
{
  if(!mWheelOdomManager)
    this->InitWheelOdom();
  mWheelOdomManager->SetRelative(isRelative);
}

// IMU gravity
//-----------------------------------------------------------------------------
double Slam::GetGravityWeight() const
{
  if(mGravityManager)
    return mGravityManager->GetWeight();
  PRINT_ERROR("IMU has not been set : can't get IMU weight")
  return 0.;
}

//-----------------------------------------------------------------------------
void Slam::SetGravityWeight(double weight)
{
  if(!mGravityManager)
    this->InitGravity();
  mGravityManager->SetWeight(weight);
}

// Landmark detector
//-----------------------------------------------------------------------------
void Slam::SetLandmarkWeight(double weight)
{
  for (auto& idLm : mLandmarksManagers)
    idLm.second.SetWeight(weight);
  mLandmarkWeight = weight;
}

//-----------------------------------------------------------------------------
void Slam::SetLandmarkSaturationDistance(float dist)
{
  for (auto& idLm : mLandmarksManagers)
    idLm.second.SetSaturationDistance(dist);
  mLandmarkSaturationDistance = dist;
}

//-----------------------------------------------------------------------------
void Slam::SetLandmarkPositionOnly(bool positionOnly)
{
  for (auto& idLm : mLandmarksManagers)
    idLm.second.SetPositionOnly(positionOnly);
  mLandmarkPositionOnly = positionOnly;
}

//-----------------------------------------------------------------------------
void Slam::SetLandmarkCovarianceRotation(bool rotate)
{
  for (auto& idLm : mLandmarksManagers)
    idLm.second.SetCovarianceRotation(rotate);
  mLandmarkCovarianceRotation = rotate;
}

// Pose
//-----------------------------------------------------------------------------
double Slam::GetPoseWeight() const
{
  if (mPoseManager)
    return mPoseManager->GetWeight();
  PRINT_ERROR("Pose sensor has not been set : can't get pose weight")
  return 0.;
}

//-----------------------------------------------------------------------------
void Slam::SetPoseWeight(double weight)
{
  if (!mPoseManager)
    this->InitPoseSensor();
  mPoseManager->SetWeight(weight);
}

//==============================================================================
//   Keypoints extraction parameters setting
//==============================================================================

//-----------------------------------------------------------------------------
std::map<uint8_t, Slam::KeypointExtractorPtr> Slam::GetKeyPointsExtractors() const
{
  return mKeyPointsExtractors;
}

void Slam::SetKeyPointsExtractors(const std::map<uint8_t, KeypointExtractorPtr>& extractors)
{
  mKeyPointsExtractors = extractors;
}

//-----------------------------------------------------------------------------
Slam::KeypointExtractorPtr Slam::GetKeyPointsExtractor(uint8_t deviceId) const
{
  return mKeyPointsExtractors.count(deviceId) ? mKeyPointsExtractors.at(deviceId) : KeypointExtractorPtr();
}

void Slam::SetKeyPointsExtractor(KeypointExtractorPtr extractor, uint8_t deviceId)
{
  mKeyPointsExtractors[deviceId] = extractor;
}

//-----------------------------------------------------------------------------
Eigen::Isometry3d Slam::GetBaseToLidarOffset(uint8_t deviceId) const
{
  return mBaseToLidarOffsets.count(deviceId) ? mBaseToLidarOffsets.at(deviceId) : Eigen::UnalignedIsometry3d::Identity();
}

void Slam::SetBaseToLidarOffset(const Eigen::Isometry3d& transform, uint8_t deviceId)
{
  mBaseToLidarOffsets[deviceId] = transform;
}

//==============================================================================
//   Rolling grids parameters setting
//==============================================================================

//-----------------------------------------------------------------------------
void Slam::ClearMaps()
{
  for (auto kmap: mLocalMaps)
    kmap.second->Reset();
}

//-----------------------------------------------------------------------------
double Slam::GetVoxelGridDecayingThreshold() const
{
  return mLocalMaps.begin()->second->GetDecayingThreshold();
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridDecayingThreshold(double decay)
{
  for (auto k : mUsableKeypoints)
    mLocalMaps[k]->SetDecayingThreshold(decay);
}

//-----------------------------------------------------------------------------
SamplingMode Slam::GetVoxelGridSamplingMode(Keypoint k) const
{
  return mLocalMaps.at(k)->GetSampling();
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridSamplingMode(Keypoint k, SamplingMode sm)
{
  mLocalMaps[k]->SetSampling(sm);
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridLeafSize(Keypoint k, double size)
{
  mLocalMaps[k]->SetLeafSize(size);
}

//-----------------------------------------------------------------------------
double Slam::GetVoxelGridLeafSize(Keypoint k) const
{
  return mLocalMaps.at(k)->GetLeafSize();
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridSize(int size)
{
  for (auto k : mUsableKeypoints)
    mLocalMaps[k]->SetGridSize(size);
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridResolution(double resolution)
{
  for (auto k : mUsableKeypoints)
    mLocalMaps[k]->SetVoxelResolution(resolution);
}

//-----------------------------------------------------------------------------
void Slam::SetVoxelGridMinFramesPerVoxel(unsigned int minFrames)
{
  for (auto k : mUsableKeypoints)
    mLocalMaps[k]->SetMinFramesPerVoxel(minFrames);
}

//==============================================================================
//   Memory parameters setting
//==============================================================================

//-----------------------------------------------------------------------------
void Slam::SetLoggingTimeout(double lMax)
{
  mLoggingTimeout = lMax;
  if (mLogStates.empty())
      return;

  double currentTime = mLogStates.back().Time;
  auto itSt = mLogStates.begin();
  while (currentTime - itSt->Time > lMax && mLogStates.size() > 2)
  {
    ++itSt;
    mLogStates.pop_front();
  }
}

} // end of LidarSlam namespace